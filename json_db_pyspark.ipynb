{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "json-db-pyspark.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOhOshyBKH3TvOKPWLOvBFI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jpcloud2021/pyspark-exm/blob/main/json_db_pyspark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EGxse_qO1wJ"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfKqqISdPP53",
        "outputId": "87e09af5-e024-46c9-f8fd-802716706318"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/db/e18cfd78e408de957821ec5ca56de1250645b05f8523d169803d8df35a64/pyspark-3.1.2.tar.gz (212.4MB)\n",
            "\u001b[K     |████████████████████████████████| 212.4MB 67kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 18.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=55387d468d53af12a4293ad6ae41eadf9ed38568508a2d794eeaefa7a03ecbcd\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/1b/2c/30f43be2627857ab80062bef1527c0128f7b4070b6b2d02139\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIEpRboNPI6v"
      },
      "source": [
        "#test_emp.json\n",
        "data=[{\n",
        "   \"data\": {\n",
        "       \"emp_id\": \"12345\",\n",
        "       \"emp_name\": \"Mohan\",\n",
        "       \"awards\": [\n",
        "           {\n",
        "               \"award_type\": \"Internal-1\",\n",
        "               \"award_name\": \"Best_emp_of_the_year_1\",\n",
        "               \"year\": \"2001\"\n",
        "           },\n",
        "           {\n",
        "               \"award_type\": \"Internal-2\",\n",
        "               \"award_name\": \"Best_emp_of_the_year_2\",\n",
        "               \"year\": \"2002\"\n",
        "           },\n",
        "           {\n",
        "               \"award_type\": \"Internal-3\",\n",
        "               \"award_name\": \"Best_emp_of_the_year_3\",\n",
        "               \"year\": \"2003\"\n",
        "           },\n",
        "           {\n",
        "               \"award_type\": \"External\",\n",
        "               \"award_name\": \"Best_presenter\",\n",
        "               \"year\": \"2001\"\n",
        "           }\n",
        "       ]\n",
        "   }\n",
        "}]\n",
        "\n",
        "#main.py\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import ArrayType, StringType, StructType\n",
        " \n",
        "schema = StructType() \\\n",
        "             .add(\"data\", StructType() \\\n",
        "                   .add(\"emp_id\", StringType(),True) \\\n",
        "                   .add(\"emp_name\", StringType(), True) \\\n",
        "                   .add(\"awards\", ArrayType(StructType()                     \n",
        "                       .add(\"award_type\", StringType(), True) \\\n",
        "                       .add(\"award_name\", StringType(), True))) \\\n",
        "               , True)\n",
        " \n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hql_BCDTSzBS",
        "outputId": "dab49271-d1f5-4ff6-d874-7a1e4b4e1b01"
      },
      "source": [
        "spark= SparkSession.builder\\\n",
        ".appName(\"MyJsonProcess\")\\\n",
        ".master(\"local[*]\")\\\n",
        ".getOrCreate()\n",
        "\n",
        "spark\n",
        " \n",
        "df1 = spark.createDataFrame(data=data,schema=schema)\n",
        "df1.show(truncate=False)\n",
        "df1.printSchema()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|data                                                                                                                                                          |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|{12345, Mohan, [{Internal-1, Best_emp_of_the_year_1}, {Internal-2, Best_emp_of_the_year_2}, {Internal-3, Best_emp_of_the_year_3}, {External, Best_presenter}]}|\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "root\n",
            " |-- data: struct (nullable = true)\n",
            " |    |-- emp_id: string (nullable = true)\n",
            " |    |-- emp_name: string (nullable = true)\n",
            " |    |-- awards: array (nullable = true)\n",
            " |    |    |-- element: struct (containsNull = true)\n",
            " |    |    |    |-- award_type: string (nullable = true)\n",
            " |    |    |    |-- award_name: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0FlvL5sWk1j",
        "outputId": "b095f62d-bf5a-4a96-e75e-f39d0b217e9d"
      },
      "source": [
        "#df1.select(df1.emp_id).filter(df1.emp_id ==12345).show()\n",
        "df1.select(\"data.emp_name\").show()\n",
        "df1.select(\"data.awards.award_name\").show()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+\n",
            "|emp_name|\n",
            "+--------+\n",
            "|   Mohan|\n",
            "+--------+\n",
            "\n",
            "+--------------------+\n",
            "|          award_name|\n",
            "+--------------------+\n",
            "|[Best_emp_of_the_...|\n",
            "+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2N-f8rOWlEA",
        "outputId": "396b5159-db26-4701-9a2d-57e4ba615945"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql.functions import explode\n",
        "\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "json_data = '{\"results\":[{\"a\":1,\"b\":2,\"c\":\"name\"},{\"a\":2,\"b\":5,\"c\":\"foo\"}]}'\n",
        "json_rdd = sc.parallelize([json_data])\n",
        "df = spark.read.json(json_rdd)\n",
        "df =df.withColumn(\"results\", explode(df.results)).select( \n",
        "                         col(\"results.a\").alias(\"a\"),\n",
        "                         col(\"results.b\").alias(\"b\"),\n",
        "                         col(\"results.c\").alias(\"c\") ) \n",
        "df.show()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---+----+\n",
            "|  a|  b|   c|\n",
            "+---+---+----+\n",
            "|  1|  2|name|\n",
            "|  2|  5| foo|\n",
            "+---+---+----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wlox_e3WWlHh",
        "outputId": "265d5660-a205-424c-cbd7-6d42628eec14"
      },
      "source": [
        "df.filter(df.c =='name').show()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---+----+\n",
            "|  a|  b|   c|\n",
            "+---+---+----+\n",
            "|  1|  2|name|\n",
            "+---+---+----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Wkbh0anWlMR",
        "outputId": "a375b139-abb0-4cb0-fe75-c60965fdb0a3"
      },
      "source": [
        "stringJSONRDD = sc.parallelize((\"\"\" \n",
        "  { \"id\": \"123\",\n",
        "    \"name\": \"Katie\",\n",
        "    \"age\": 19,\n",
        "    \"eyeColor\": \"brown\"\n",
        "  }\"\"\",\n",
        "   \"\"\"{\n",
        "    \"id\": \"234\",\n",
        "    \"name\": \"Michael\",\n",
        "    \"age\": 22,\n",
        "    \"eyeColor\": \"green\"\n",
        "  }\"\"\", \n",
        "  \"\"\"{\n",
        "    \"id\": \"345\",\n",
        "    \"name\": \"Simone\",\n",
        "    \"age\": 23,\n",
        "    \"eyeColor\": \"blue\"\n",
        "  }\"\"\")\n",
        ")\n",
        "#Then Create DataFrame\n",
        "\n",
        "swimmersJSON = spark.read.json(stringJSONRDD)\n",
        "swimmersJSON.printSchema()\n",
        "swimmersJSON.show()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- age: long (nullable = true)\n",
            " |-- eyeColor: string (nullable = true)\n",
            " |-- id: string (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            "\n",
            "+---+--------+---+-------+\n",
            "|age|eyeColor| id|   name|\n",
            "+---+--------+---+-------+\n",
            "| 19|   brown|123|  Katie|\n",
            "| 22|   green|234|Michael|\n",
            "| 23|    blue|345| Simone|\n",
            "+---+--------+---+-------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWV4vvJWWlO_",
        "outputId": "70898bfe-6bca-4091-ff5e-b2a706c3d5f1"
      },
      "source": [
        "swimmersJSON.where(col('name').like(\"%a%\")).show()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+--------+---+-------+\n",
            "|age|eyeColor| id|   name|\n",
            "+---+--------+---+-------+\n",
            "| 19|   brown|123|  Katie|\n",
            "| 22|   green|234|Michael|\n",
            "+---+--------+---+-------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tRMa5QHWlRr",
        "outputId": "d5adeec9-b5bc-4d0b-e0c4-09a0a7042949"
      },
      "source": [
        "swimmersJSON.where(col('name').like(\"_a%\")).show()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+--------+---+-----+\n",
            "|age|eyeColor| id| name|\n",
            "+---+--------+---+-----+\n",
            "| 19|   brown|123|Katie|\n",
            "+---+--------+---+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DShYN6YzWlUe",
        "outputId": "eac7ad51-4eb4-4507-f18d-47dadad5ef2e"
      },
      "source": [
        "swimmersJSON.where(col('name').like(\"___i%\")).show()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+--------+---+-----+\n",
            "|age|eyeColor| id| name|\n",
            "+---+--------+---+-----+\n",
            "| 19|   brown|123|Katie|\n",
            "+---+--------+---+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNL_EmwAWlX8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}