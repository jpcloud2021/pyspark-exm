{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyspark-sample-0907.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jpcloud2021/pyspark-exm/blob/main/pyspark_sample_0907.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCLcAMeIu5cz",
        "outputId": "64aa448a-c5cf-4091-a5d8-d4ba7a18e296"
      },
      "source": [
        "!pip install pyspark\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/db/e18cfd78e408de957821ec5ca56de1250645b05f8523d169803d8df35a64/pyspark-3.1.2.tar.gz (212.4MB)\n",
            "\u001b[K     |████████████████████████████████| 212.4MB 72kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 17.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=605a7b8eebb1fd209c262853c6f14bd1602c8b5d8d96abf34b4cd237d2c2add9\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/1b/2c/30f43be2627857ab80062bef1527c0128f7b4070b6b2d02139\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlND-6_Jwyui",
        "outputId": "57f12cdb-7a30-4685-b4b0-49a73c80a4fc"
      },
      "source": [
        "list1 = (1,2,3,4)\n",
        "list1\n",
        "list1[2]\n",
        "\n",
        "myDict ={\"1\":\"Bob\",\"2\":\"Cooper\",\"3\":\"John\"}\n",
        "myDict\n",
        "myDict.keys()\n",
        "myDict.values()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_values(['Bob', 'Cooper', 'John'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFh9ksHZzTDX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "dc7b1a59-5aed-421a-c03b-acf595cb75c8"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark= SparkSession.builder\\\n",
        ".appName(\"MyProcess\")\\\n",
        ".master(\"local[*]\")\\\n",
        ".getOrCreate()\n",
        "spark"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://2298c915a439:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>MyProcess</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f8ae5023fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFiLbp5T1I6A"
      },
      "source": [
        "### creating dataframe\n",
        "\n",
        "header =[\"city\",\"type\",\"price\"]\n",
        "\n",
        "data =map(lambda r:(r[0],r[1],float(r[2])),\n",
        "                    map(lambda x:x.split(\",\"),\n",
        "                        [\"Paris,Food,19.0\", \"marsellie,Cloathing,12.0\", \"Paris,Food,8.0\", \"Paris,Cloathing,8.0\"]))\n",
        "df=spark.createDataFrame(data,header)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjuMA4MOuDPO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb6sRrlDuDSj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuYjCcQaDUZe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "393004ea-7662-4f2a-cd93-ab00cb1f7fbd"
      },
      "source": [
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+---------+-----+\n",
            "|     city|     type|price|\n",
            "+---------+---------+-----+\n",
            "|    Paris|     Food| 19.0|\n",
            "|marsellie|Cloathing| 12.0|\n",
            "|    Paris|     Food|  8.0|\n",
            "|    Paris|Cloathing|  8.0|\n",
            "+---------+---------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fCt3WnruFOO",
        "outputId": "18ee34a2-9f0c-4b3a-b1ef-6d5e41f61a87"
      },
      "source": [
        "from pyspark.sql.types import StringType, FloatType, StructType , StructField\n",
        "\n",
        "data =map(lambda r:(r[0],r[1],float(r[2])),\n",
        "\tmap(lambda x:x.split(\",\"),\n",
        "[\"Paris,Food,19.00\", \n",
        "\"Marsellie,Cloathing,12.00\", \n",
        "\"Paris,Food,8.00\", \n",
        "\"Paris,Cloathing,8.00\",\n",
        "\"Marsellie,Food,20.00\",\n",
        "\"Lyon,Book,18.00\"]))\n",
        "\n",
        "schema = StructType([StructField(\"city\", StringType(), nullable=True),StructField(\"type\", StringType(), nullable=True),StructField(\"price\", FloatType(), nullable=True)])\n",
        "\n",
        "df =spark.createDataFrame(data,schema=schema)\n",
        "df.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+---------+-----+\n",
            "|     city|     type|price|\n",
            "+---------+---------+-----+\n",
            "|    Paris|     Food| 19.0|\n",
            "|Marsellie|Cloathing| 12.0|\n",
            "|    Paris|     Food|  8.0|\n",
            "|    Paris|Cloathing|  8.0|\n",
            "|Marsellie|     Food| 20.0|\n",
            "|     Lyon|     Book| 18.0|\n",
            "+---------+---------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubPimgL_uNZe",
        "outputId": "ea1241bf-7d07-4222-8a33-e29a5112255a"
      },
      "source": [
        "from pyspark.sql.types import StringType, FloatType, StructType , StructField\n",
        "\n",
        "data =map(lambda r:(r[0],r[1],float(r[2])),\n",
        "\tmap(lambda x:x.split(\",\"),\n",
        "[\"Paris,Food,19.00\", \n",
        "\"Marsellie,Cloathing,12.00\", \n",
        "\"Paris,Food,8.00\", \n",
        "\"Paris,Cloathing,8.00\",\n",
        "\"Marsellie,Food,20.00\",\n",
        "\"Lyon,Book,18.00\"]))\n",
        "\n",
        "schema = StructType([StructField(\"city\", StringType(), nullable=True),StructField(\"type\", StringType(), nullable=True),StructField(\"price\", FloatType(), nullable=True)])\n",
        "\n",
        "df =spark.createDataFrame(data,schema=schema)\n",
        "df.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+---------+-----+\n",
            "|     city|     type|price|\n",
            "+---------+---------+-----+\n",
            "|    Paris|     Food| 19.0|\n",
            "|Marsellie|Cloathing| 12.0|\n",
            "|    Paris|     Food|  8.0|\n",
            "|    Paris|Cloathing|  8.0|\n",
            "|Marsellie|     Food| 20.0|\n",
            "|     Lyon|     Book| 18.0|\n",
            "+---------+---------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gq38vHgTuNdG",
        "outputId": "132922db-e9f3-4fc8-bdf5-52a3788d591d"
      },
      "source": [
        "\n",
        "#manipulating column\n",
        "\n",
        "from pyspark.sql.types import StringType, FloatType, StructType , StructField\n",
        "\n",
        "data =map(lambda r:(r[0],r[1],float(r[2])),\n",
        "\tmap(lambda x:x.split(\",\"),\n",
        "[\"Paris,Food,19.00\", \n",
        "\"Marsellie,Cloathing,12.00\", \n",
        "\"Paris,Food,8.00\", \n",
        "\"Paris,Cloathing,8.00\",\n",
        "\"Marsellie,Food,20.00\",\n",
        "\"Lyon,Book,18.00\"]))\n",
        "\n",
        "schema = StructType([StructField(\"city\", StringType(), nullable=True),StructField(\"type\", StringType(), nullable=True),StructField(\"price\", FloatType(), nullable=True)])\n",
        "\n",
        "df =spark.createDataFrame(data,schema=schema)\n",
        "df.show()\n",
        "\n",
        "df.withColumn(\"abc\", df.price /2).show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+---------+-----+\n",
            "|     city|     type|price|\n",
            "+---------+---------+-----+\n",
            "|    Paris|     Food| 19.0|\n",
            "|Marsellie|Cloathing| 12.0|\n",
            "|    Paris|     Food|  8.0|\n",
            "|    Paris|Cloathing|  8.0|\n",
            "|Marsellie|     Food| 20.0|\n",
            "|     Lyon|     Book| 18.0|\n",
            "+---------+---------+-----+\n",
            "\n",
            "+---------+---------+-----+----+\n",
            "|     city|     type|price| abc|\n",
            "+---------+---------+-----+----+\n",
            "|    Paris|     Food| 19.0| 9.5|\n",
            "|Marsellie|Cloathing| 12.0| 6.0|\n",
            "|    Paris|     Food|  8.0| 4.0|\n",
            "|    Paris|Cloathing|  8.0| 4.0|\n",
            "|Marsellie|     Food| 20.0|10.0|\n",
            "|     Lyon|     Book| 18.0| 9.0|\n",
            "+---------+---------+-----+----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPCmjBCDuNgZ",
        "outputId": "272eb623-402d-4c13-9a87-704d577e2fb8"
      },
      "source": [
        "from pyspark.sql.functions import cos\n",
        "\n",
        "df = spark.createDataFrame([[1, 2],[2, 3],[3, 4],[4, 5]], schema=[\"x1\",\"x2\"])\n",
        "\n",
        "df.withColumn(\"cos_sum\", cos(df.x1 +df.x2)).show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---+-------------------+\n",
            "| x1| x2|            cos_sum|\n",
            "+---+---+-------------------+\n",
            "|  1|  2|-0.9899924966004454|\n",
            "|  2|  3|0.28366218546322625|\n",
            "|  3|  4| 0.7539022543433046|\n",
            "|  4|  5|-0.9111302618846769|\n",
            "+---+---+-------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ylYIEUYuNkH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61ZIT-5CuNnZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oxj20y1huNqF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WPT5BEKuNtf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}